#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import signal
import sys
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from pytz import timezone
from datetime import datetime

from logger_config import logger
from crawler_service import crawler_service
from config import SCHEDULE_CONFIG

class CrawlerScheduler:
    def __init__(self):
        self.scheduler = BlockingScheduler(
            timezone=timezone(SCHEDULE_CONFIG["timezone"])
        )
        self.setup_signal_handlers()
        self.setup_jobs()
    
    def setup_signal_handlers(self):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì • (ìš°ì•„í•œ ì¢…ë£Œ)"""
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def signal_handler(self, signum, frame):
        """ì‹œê·¸ë„ ì²˜ë¦¬ (Ctrl+C ë“±)"""
        logger.info(f"ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹  ({signum}). ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì •ë¦¬í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤...")
        self.shutdown()
        sys.exit(0)
    
    def setup_jobs(self):
        """ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì •"""
        if not SCHEDULE_CONFIG["enabled"]:
            logger.warning("ìŠ¤ì¼€ì¤„ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return
        
        for i, schedule in enumerate(SCHEDULE_CONFIG["schedules"]):
            job_id = f"crawl_job_{i}"
            
            if schedule["type"] == "cron":
                trigger = CronTrigger(
                    hour=schedule.get("hour"),
                    minute=schedule.get("minute", 0),
                    timezone=SCHEDULE_CONFIG["timezone"]
                )
                schedule_desc = f"ë§¤ì¼ {schedule['hour']:02d}:{schedule.get('minute', 0):02d}"
                
            elif schedule["type"] == "interval":
                trigger = IntervalTrigger(
                    hours=schedule.get("hours", 0),
                    minutes=schedule.get("minutes", 0),
                    seconds=schedule.get("seconds", 0)
                )
                schedule_desc = f"ë§¤ {schedule.get('hours', 0)}ì‹œê°„ {schedule.get('minutes', 0)}ë¶„ë§ˆë‹¤"            
            else:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¤„ íƒ€ì…: {schedule['type']}")
                continue
            
            self.scheduler.add_job(
                func=self.crawl_job,
                trigger=trigger,
                id=job_id,
                name=f"ì¡°ì„ ëŒ€ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ - {schedule_desc}",
                max_instances=1,
                coalesce=True
            )
            
            logger.info(f"ìŠ¤ì¼€ì¤„ ë“±ë¡: {schedule_desc}")
    
    def crawl_job(self):
        """í¬ë¡¤ë§ ì‘ì—… ì‹¤í–‰"""
        try:
            logger.info("="*60)
            logger.info("ğŸ“¢ ì˜ˆì•½ëœ ì¡°ì„ ëŒ€ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì‘ì—… ì‹œì‘")
            start_time = datetime.now()
            
            total_notices = crawler_service.crawl_all_categories()
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            logger.info(f"âœ… í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ, ì²˜ë¦¬ëœ ê³µì§€ì‚¬í•­: {total_notices}ê°œ)")
            logger.info("="*60)
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì•½ëœ í¬ë¡¤ë§ ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")
    
    def run_once(self):
        """ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)"""
        logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤í–‰...")
        self.crawl_job()
    
    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        logger.info("ğŸš€ ì¡°ì„ ëŒ€ ê³µì§€ì‚¬í•­ ìë™ í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
        logger.info(f"ì„¤ì •ëœ ì‘ì—… ìˆ˜: {len(self.scheduler.get_jobs())}")
        
        try:
            self.scheduler.start()
        except KeyboardInterrupt:
            logger.info("ì‚¬ìš©ìì— ì˜í•œ ì¢…ë£Œ ìš”ì²­")
            self.shutdown()
    
    def shutdown(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ"""
        if self.scheduler.running:
            self.scheduler.shutdown(wait=True)
            logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì¡°ì„ ëŒ€í•™êµ ê³µì§€ì‚¬í•­ ìë™ í¬ë¡¤ë§ ì‹œìŠ¤í…œ")
    parser.add_argument("--test", action="store_true", help="ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)")
    parser.add_argument("--debug", action="store_true", help="ë””ë²„ê·¸ ëª¨ë“œ")
    
    args = parser.parse_args()
    
    if args.debug:
        import logging
        logging.getLogger("apscheduler").setLevel(logging.DEBUG)
    
    scheduler_instance = CrawlerScheduler()
    
    if args.test:
        scheduler_instance.run_once()
    else:
        scheduler_instance.start()

if __name__ == "__main__":
    main()